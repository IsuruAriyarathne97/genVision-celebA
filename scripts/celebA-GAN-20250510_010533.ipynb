{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfbcfb9f",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [8]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c17eef2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T05:05:34.902115Z",
     "iopub.status.busy": "2025-05-10T05:05:34.901561Z",
     "iopub.status.idle": "2025-05-10T05:05:39.264051Z",
     "shell.execute_reply": "2025-05-10T05:05:39.262911Z"
    },
    "papermill": {
     "duration": 4.373334,
     "end_time": "2025-05-10T05:05:39.265289",
     "exception": false,
     "start_time": "2025-05-10T05:05:34.891955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c124146",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T05:05:39.274110Z",
     "iopub.status.busy": "2025-05-10T05:05:39.273351Z",
     "iopub.status.idle": "2025-05-10T05:05:39.368500Z",
     "shell.execute_reply": "2025-05-10T05:05:39.367767Z"
    },
    "papermill": {
     "duration": 0.099979,
     "end_time": "2025-05-10T05:05:39.369349",
     "exception": false,
     "start_time": "2025-05-10T05:05:39.269370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78c0bedf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T05:05:39.377125Z",
     "iopub.status.busy": "2025-05-10T05:05:39.376491Z",
     "iopub.status.idle": "2025-05-10T05:05:48.706225Z",
     "shell.execute_reply": "2025-05-10T05:05:48.705206Z"
    },
    "papermill": {
     "duration": 9.334153,
     "end_time": "2025-05-10T05:05:48.707185",
     "exception": false,
     "start_time": "2025-05-10T05:05:39.373032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sciclone/data10/iahewababarand/genVision-celebA/gen-env/lib64/python3.11/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "image_dir = \"celebA/celeba/img_align_celeba\"\n",
    "os.makedirs(\"test\", exist_ok=True)\n",
    "os.makedirs(\"gan_outputs\", exist_ok=True)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop(160),\n",
    "    transforms.Resize(64),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=image_dir, transform=transform)\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "random.seed(42)\n",
    "random.shuffle(indices)\n",
    "split = int(0.1 * dataset_size)\n",
    "val_indices, train_indices = indices[:split], indices[split:]\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=3000, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=3000, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0e144b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T05:05:48.716563Z",
     "iopub.status.busy": "2025-05-10T05:05:48.715916Z",
     "iopub.status.idle": "2025-05-10T05:05:48.727284Z",
     "shell.execute_reply": "2025-05-10T05:05:48.726544Z"
    },
    "papermill": {
     "duration": 0.016681,
     "end_time": "2025-05-10T05:05:48.728145",
     "exception": false,
     "start_time": "2025-05-10T05:05:48.711464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Models\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=100, img_channels=3, features_g=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.ConvTranspose2d(z_dim, features_g * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(features_g * 8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(features_g * 8, features_g * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(features_g * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(features_g * 4, features_g * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(features_g * 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(features_g * 2, features_g, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(features_g),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(features_g, img_channels, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.net(z)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_channels=3, features_d=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(img_channels, features_d, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(features_d, features_d * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(features_d * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(features_d * 2, features_d * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(features_d * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(features_d * 4, features_d * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(features_d * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(features_d * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.net(img).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26a56cb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T05:05:48.737540Z",
     "iopub.status.busy": "2025-05-10T05:05:48.736925Z",
     "iopub.status.idle": "2025-05-10T05:05:48.740423Z",
     "shell.execute_reply": "2025-05-10T05:05:48.739645Z"
    },
    "papermill": {
     "duration": 0.009305,
     "end_time": "2025-05-10T05:05:48.741256",
     "exception": false,
     "start_time": "2025-05-10T05:05:48.731951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "z_dim = 100\n",
    "lr = 2e-4\n",
    "n_epochs = 50\n",
    "batch_size = 3000\n",
    "early_stop_patience = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be104b29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T05:05:48.749519Z",
     "iopub.status.busy": "2025-05-10T05:05:48.748919Z",
     "iopub.status.idle": "2025-05-10T05:05:49.043371Z",
     "shell.execute_reply": "2025-05-10T05:05:49.042361Z"
    },
    "papermill": {
     "duration": 0.300099,
     "end_time": "2025-05-10T05:05:49.044464",
     "exception": false,
     "start_time": "2025-05-10T05:05:48.744365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "G = Generator(z_dim).to(device)\n",
    "D = Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "594863f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T05:05:49.053670Z",
     "iopub.status.busy": "2025-05-10T05:05:49.053003Z",
     "iopub.status.idle": "2025-05-10T05:05:49.058933Z",
     "shell.execute_reply": "2025-05-10T05:05:49.058147Z"
    },
    "papermill": {
     "duration": 0.011113,
     "end_time": "2025-05-10T05:05:49.059776",
     "exception": false,
     "start_time": "2025-05-10T05:05:49.048663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "fixed_noise = torch.randn(64, z_dim, 1, 1, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe6d31f",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1fa76a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T05:05:49.068754Z",
     "iopub.status.busy": "2025-05-10T05:05:49.068133Z",
     "iopub.status.idle": "2025-05-10T05:08:17.934734Z",
     "shell.execute_reply": "2025-05-10T05:08:17.933431Z"
    },
    "papermill": {
     "duration": 148.872024,
     "end_time": "2025-05-10T05:08:17.935336",
     "exception": true,
     "start_time": "2025-05-10T05:05:49.063312",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:   0%|          | 0/61 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:   2%|▏         | 1/61 [00:14<14:29, 14.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:   3%|▎         | 2/61 [00:14<06:06,  6.22s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:   5%|▍         | 3/61 [00:15<03:27,  3.58s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:   7%|▋         | 4/61 [00:15<02:13,  2.35s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:   8%|▊         | 5/61 [00:21<03:11,  3.43s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  10%|▉         | 6/61 [00:21<02:19,  2.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  11%|█▏        | 7/61 [00:22<01:39,  1.85s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  13%|█▎        | 8/61 [00:22<01:14,  1.40s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  15%|█▍        | 9/61 [00:30<03:02,  3.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  16%|█▋        | 10/61 [00:31<02:15,  2.65s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  18%|█▊        | 11/61 [00:32<01:38,  1.98s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  20%|█▉        | 12/61 [00:32<01:14,  1.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  21%|██▏       | 13/61 [00:40<02:47,  3.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  23%|██▎       | 14/61 [00:41<02:02,  2.60s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  25%|██▍       | 15/61 [00:41<01:29,  1.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  26%|██▌       | 16/61 [00:42<01:07,  1.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  28%|██▊       | 17/61 [00:50<02:33,  3.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  30%|██▉       | 18/61 [00:50<01:54,  2.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  31%|███       | 19/61 [00:51<01:23,  2.00s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  33%|███▎      | 20/61 [00:51<01:02,  1.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  34%|███▍      | 21/61 [00:59<02:15,  3.40s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  36%|███▌      | 22/61 [01:00<01:40,  2.58s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  38%|███▊      | 23/61 [01:00<01:13,  1.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  39%|███▉      | 24/61 [01:01<00:55,  1.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  41%|████      | 25/61 [01:09<02:04,  3.46s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  43%|████▎     | 26/61 [01:09<01:31,  2.61s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  44%|████▍     | 27/61 [01:10<01:06,  1.96s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  46%|████▌     | 28/61 [01:10<00:49,  1.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  48%|████▊     | 29/61 [01:18<01:51,  3.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  49%|████▉     | 30/61 [01:19<01:20,  2.61s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  51%|█████     | 31/61 [01:19<00:58,  1.96s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  52%|█████▏    | 32/61 [01:20<00:43,  1.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  54%|█████▍    | 33/61 [01:28<01:35,  3.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  56%|█████▌    | 34/61 [01:28<01:11,  2.65s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  57%|█████▋    | 35/61 [01:29<00:51,  1.99s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  59%|█████▉    | 36/61 [01:29<00:38,  1.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  61%|██████    | 37/61 [01:37<01:21,  3.39s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  62%|██████▏   | 38/61 [01:38<00:59,  2.60s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  64%|██████▍   | 39/61 [01:38<00:43,  1.96s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  66%|██████▌   | 40/61 [01:39<00:31,  1.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  67%|██████▋   | 41/61 [01:47<01:09,  3.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  69%|██████▉   | 42/61 [01:48<00:50,  2.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  70%|███████   | 43/61 [01:48<00:36,  2.00s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  72%|███████▏  | 44/61 [01:49<00:26,  1.54s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  74%|███████▍  | 45/61 [01:56<00:54,  3.40s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  75%|███████▌  | 46/61 [01:57<00:40,  2.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  77%|███████▋  | 47/61 [01:58<00:27,  2.00s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  79%|███████▊  | 48/61 [01:58<00:19,  1.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  80%|████████  | 49/61 [02:06<00:40,  3.41s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  82%|████████▏ | 50/61 [02:07<00:29,  2.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  84%|████████▎ | 51/61 [02:07<00:20,  2.02s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  85%|████████▌ | 52/61 [02:08<00:13,  1.55s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  87%|████████▋ | 53/61 [02:15<00:26,  3.31s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  89%|████████▊ | 54/61 [02:17<00:19,  2.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  90%|█████████ | 55/61 [02:17<00:12,  2.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  92%|█████████▏| 56/61 [02:18<00:07,  1.57s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  93%|█████████▎| 57/61 [02:25<00:13,  3.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  95%|█████████▌| 58/61 [02:26<00:07,  2.61s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  97%|█████████▋| 59/61 [02:26<00:03,  1.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  98%|█████████▊| 60/61 [02:27<00:01,  1.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/50:  98%|█████████▊| 60/61 [02:28<00:02,  2.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([3000])) that is different to the input size (torch.Size([2340])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m output_real \u001b[38;5;241m=\u001b[39m D(real_imgs)\n\u001b[1;32m     24\u001b[0m output_fake \u001b[38;5;241m=\u001b[39m D(fake_imgs\u001b[38;5;241m.\u001b[39mdetach())\n\u001b[0;32m---> 25\u001b[0m loss_D \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_real\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_labels\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m criterion(output_fake, fake_labels)\n\u001b[1;32m     27\u001b[0m optimizer_D\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     28\u001b[0m loss_D\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/sciclone/data10/iahewababarand/genVision-celebA/gen-env/lib64/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/sciclone/data10/iahewababarand/genVision-celebA/gen-env/lib64/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/sciclone/data10/iahewababarand/genVision-celebA/gen-env/lib64/python3.11/site-packages/torch/nn/modules/loss.py:699\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/sciclone/data10/iahewababarand/genVision-celebA/gen-env/lib64/python3.11/site-packages/torch/nn/functional.py:3560\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3558\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize():\n\u001b[0;32m-> 3560\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3561\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3562\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3563\u001b[0m     )\n\u001b[1;32m   3565\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3566\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n",
      "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([3000])) that is different to the input size (torch.Size([2340])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "train_g_losses = []\n",
    "val_g_losses = []\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(n_epochs):\n",
    "    g_loss_epoch = 0.0\n",
    "    d_loss_epoch = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    G.train()\n",
    "    for real_imgs, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{n_epochs}\"):\n",
    "        real_imgs = real_imgs.to(device)\n",
    "\n",
    "        # Train Discriminator\n",
    "        z = torch.randn(batch_size, z_dim, 1, 1, device=device)\n",
    "        fake_imgs = G(z)\n",
    "\n",
    "        real_labels = torch.ones(batch_size, device=device)\n",
    "        fake_labels = torch.zeros(batch_size, device=device)\n",
    "\n",
    "        output_real = D(real_imgs)\n",
    "        output_fake = D(fake_imgs.detach())\n",
    "        loss_D = criterion(output_real, real_labels) + criterion(output_fake, fake_labels)\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Train Generator\n",
    "        output_fake = D(fake_imgs)\n",
    "        loss_G = criterion(output_fake, real_labels)\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        g_loss_epoch += loss_G.item()\n",
    "        d_loss_epoch += loss_D.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    # Validation step\n",
    "    G.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for real_imgs, _ in val_loader:\n",
    "            real_imgs = real_imgs.to(device)\n",
    "            batch_size = real_imgs.size(0)\n",
    "            z = torch.randn(batch_size, z_dim, 1, 1, device=device)\n",
    "            fake_imgs = G(z)\n",
    "            output_fake = D(fake_imgs)\n",
    "            loss = criterion(output_fake, torch.ones(batch_size, device=device))\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    avg_g_loss = g_loss_epoch / num_batches\n",
    "\n",
    "    train_g_losses.append(avg_g_loss)\n",
    "    val_g_losses.append(val_loss)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        samples = G(fixed_noise)\n",
    "        save_image(samples, f\"gan_outputs/epoch_{epoch+1:03d}.png\", normalize=True)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{n_epochs}]  Loss_D: {d_loss_epoch/num_batches:.4f}  Loss_G: {avg_g_loss:.4f}  Val_Loss_G: {val_loss:.4f}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(G.state_dict(), \"gan_outputs/best_generator.pth\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= early_stop_patience:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1480d34c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot losses\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, len(train_g_losses) + 1), train_g_losses, label='Training Generator Loss')\n",
    "plt.plot(range(1, len(val_g_losses) + 1), val_g_losses, label='Validation Generator Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Generator Training vs Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"gan_outputs/loss_plot.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4be545",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate final images using best generator\n",
    "os.makedirs(\"gan_outputs/generated\", exist_ok=True)\n",
    "G.load_state_dict(torch.load(\"gan_outputs/best_generator.pth\"))\n",
    "G.eval()\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0, 10000, 64), desc=\"Generating final images\"):\n",
    "        z = torch.randn(64, z_dim, 1, 1, device=device)\n",
    "        gen_imgs = G(z)\n",
    "        for j in range(gen_imgs.size(0)):\n",
    "            save_image(gen_imgs[j], f\"gan_outputs/generated/{i + j:05d}.png\", normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 165.501741,
   "end_time": "2025-05-10T05:08:19.175711",
   "environment_variables": {},
   "exception": true,
   "input_path": "celebA-GAN.ipynb",
   "output_path": "scripts/celebA-GAN-20250510_010533.ipynb",
   "parameters": {},
   "start_time": "2025-05-10T05:05:33.673970",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}